#!/usr/bin/env python3
"""
Filtragem de M√©tricas

Remove m√©tricas problem√°ticas e cria dataset limpo para an√°lises subsequentes.

Crit√©rios:
1. Remover: ‚â•20% NaN
2. Remover: Vari√¢ncia zero
3. Remover: Correla√ß√£o |r| ‚â• 0.95 (manter 1 por grupo)
4. Remover: Contagens absolutas (manter apenas propor√ß√µes)
5. Remover: M√©tricas language-specific inconsistentes
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Paths
BASE_DIR = Path(__file__).parent.parent.parent
METRICS_FILE = BASE_DIR / "metrics/full_text/individual/all_texts.csv"
QUALITY_DIR = BASE_DIR / "analysis/01_metrics_quality/data"
OUTPUT_DIR = BASE_DIR / "metrics_filtered"

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 70)
print("FILTRAGEM DE M√âTRICAS")
print("=" * 70)

# 1. Carregar dados
print("\n[1/6] Carregando dados...")
df = pd.read_csv(METRICS_FILE)
print(f"   ‚úì {len(df)} textos √ó {len(df.columns)} colunas")

# Separar metadados
metadata_cols = ['text_id', 'author', 'title', 'sample_idx', 'rep', 'condition', 'lang']
metric_cols = [col for col in df.columns if col not in metadata_cols]
print(f"   ‚úì {len(metric_cols)} m√©tricas iniciais")

# Carregar an√°lises de qualidade
nan_df = pd.read_csv(QUALITY_DIR / "nan_percentage.csv")
var_df = pd.read_csv(QUALITY_DIR / "variance_stats.csv")
corr_df = pd.read_csv(QUALITY_DIR / "correlations_high.csv")

# 2. Filtro 1: Remover m√©tricas com ‚â•20% NaN
print("\n[2/6] Filtro 1: Valores ausentes...")
problematic_nan = nan_df[nan_df['pct_nan'] >= 20]['metric'].tolist()
metrics_to_keep = [m for m in metric_cols if m not in problematic_nan]
print(f"   ‚úó Removidas: {len(problematic_nan)} m√©tricas (‚â•20% NaN)")
print(f"   ‚úì Restantes: {len(metrics_to_keep)}")

# 3. Filtro 2: Remover m√©tricas com vari√¢ncia zero
print("\n[3/6] Filtro 2: Vari√¢ncia zero...")
constant_metrics = var_df[var_df['variance'] == 0]['metric'].tolist()
metrics_to_keep = [m for m in metrics_to_keep if m not in constant_metrics]
print(f"   ‚úó Removidas: {len(constant_metrics)} m√©tricas (var=0)")
print(f"   ‚úì Restantes: {len(metrics_to_keep)}")

# 4. Filtro 3: Remover contagens absolutas (manter propor√ß√µes)
print("\n[4/6] Filtro 3: Contagens vs propor√ß√µes...")
count_metrics = [m for m in metrics_to_keep if '_count_' in m and not m.endswith('_words')]
metrics_to_keep = [m for m in metrics_to_keep if m not in count_metrics]
print(f"   ‚úó Removidas: {len(count_metrics)} contagens (manter propor√ß√µes)")
print(f"   ‚úì Restantes: {len(metrics_to_keep)}")

# 5. Filtro 4: Resolver correla√ß√µes altas (manter m√©tricas mais interpret√°veis)
print("\n[5/6] Filtro 4: Correla√ß√µes altas...")

# Regras de prefer√™ncia:
# - Propor√ß√µes > Dist√¢ncias m√©dias
# - DEPREL/UPOS props (mais interpret√°veis)
# - Remover total_words (redundante)

to_remove_corr = set()

# Priorizar propor√ß√µes sobre dist√¢ncias m√©dias
for _, row in corr_df.iterrows():
    m1, m2 = row['metric_1'], row['metric_2']
    
    # Se ambas est√£o na lista atual
    if m1 in metrics_to_keep and m2 in metrics_to_keep:
        # total_words √© redundante (mesmo valor em DEPREL e UPOS)
        if 'total_words' in m1:
            to_remove_corr.add(m1)
        elif 'total_words' in m2:
            to_remove_corr.add(m2)
        # Preferir propor√ß√£o sobre dist√¢ncia m√©dia
        elif m1.endswith('_md'):
            to_remove_corr.add(m1)
        elif m2.endswith('_md'):
            to_remove_corr.add(m2)
        # Se ambas s√£o propor√ß√µes, manter DEPREL (mais espec√≠fico)
        elif m1.startswith('synt_UPOS') and m2.startswith('synt_DEPREL'):
            to_remove_corr.add(m1)
        elif m2.startswith('synt_UPOS') and m1.startswith('synt_DEPREL'):
            to_remove_corr.add(m2)

metrics_to_keep = [m for m in metrics_to_keep if m not in to_remove_corr]
print(f"   ‚úó Removidas: {len(to_remove_corr)} m√©tricas (correla√ß√£o)")
print(f"   ‚úì Restantes: {len(metrics_to_keep)}")

# 6. Criar dataset filtrado
print("\n[6/6] Criando datasets filtrados...")

# Dataset completo
df_filtered = df[metadata_cols + metrics_to_keep].copy()
df_filtered.to_csv(OUTPUT_DIR / "all_texts_filtered.csv", index=False)
print(f"   ‚úì all_texts_filtered.csv: {len(df_filtered)} √ó {len(df_filtered.columns)}")

# Por condi√ß√£o
for condition in ['original', 'baseline', 'prompt_steering', 'activation_steering']:
    df_cond = df_filtered[df_filtered['condition'] == condition].copy()
    df_cond.to_csv(OUTPUT_DIR / f"{condition}_filtered.csv", index=False)
    print(f"   ‚úì {condition}_filtered.csv: {len(df_cond)} √ó {len(df_cond.columns)}")

# 7. Relat√≥rio de filtragem
print("\n[7/7] Gerando relat√≥rio de filtragem...")

report = f"""# Filtragem de M√©tricas

## Dados
- Arquivo original: `metrics/full_text/individual/all_texts.csv`
- M√©tricas iniciais: {len(metric_cols)}
- M√©tricas finais: {len(metrics_to_keep)}
- **Redu√ß√£o: {len(metric_cols) - len(metrics_to_keep)} m√©tricas ({(len(metric_cols) - len(metrics_to_keep))/len(metric_cols)*100:.1f}%)**

## M√©todo
Aplica√ß√£o sequencial de filtros para remover m√©tricas problem√°ticas.

## Resultados

### Pipeline de Filtragem

| Filtro | Crit√©rio | N Removidas | N Restantes |
|--------|----------|-------------|-------------|
| Inicial | - | - | {len(metric_cols)} |
| 1 | NaN ‚â• 20% | {len(problematic_nan)} | {len(metric_cols) - len(problematic_nan)} |
| 2 | Vari√¢ncia = 0 | {len(constant_metrics)} | {len(metric_cols) - len(problematic_nan) - len(constant_metrics)} |
| 3 | Contagens absolutas | {len(count_metrics)} | {len(metric_cols) - len(problematic_nan) - len(constant_metrics) - len(count_metrics)} |
| 4 | Correla√ß√£o \\|r\\| ‚â• 0.95 | {len(to_remove_corr)} | {len(metrics_to_keep)} |

### M√©tricas Finais por Categoria

**L√©xicas b√°sicas:**
"""

# Categorizar m√©tricas finais
basic_metrics = [m for m in metrics_to_keep if m.startswith('basic_')]
synt_deprel = [m for m in metrics_to_keep if 'DEPREL' in m]
synt_upos = [m for m in metrics_to_keep if 'UPOS' in m]
synt_global = [m for m in metrics_to_keep if m == 'synt_mean_dependency_distance']

report += f"\n- N = {len(basic_metrics)}"
for m in basic_metrics:
    report += f"\n  - `{m}`"

report += f"\n\n**Sint√°ticas globais:**\n- N = {len(synt_global)}"
for m in synt_global:
    report += f"\n  - `{m}`"

report += f"\n\n**DEPREL (rela√ß√µes de depend√™ncia):**\n- N = {len(synt_deprel)}"
report += f"\n- Principais: `det`, `nmod`, `obj`, `amod`, `nsubj`, `mark`, `acl`, `advmod`, `obl`, `advcl`"

report += f"\n\n**UPOS (part-of-speech):**\n- N = {len(synt_upos)}"
report += f"\n- Principais: `NOUN`, `VERB`, `ADJ`, `ADV`, `ADP`, `DET`, `PRON`, `CCONJ`, `SCONJ`"

report += f"""

## Interpreta√ß√£o T√©cnica

Redu√ß√£o de {len(metric_cols)} para {len(metrics_to_keep)} m√©tricas ({(len(metrics_to_keep)/len(metric_cols))*100:.1f}% retidos). Priorizadas m√©tricas normalizadas (propor√ß√µes), linguisticamente interpret√°veis (UPOS/DEPREL principais), e com dados completos (<20% NaN). Redund√¢ncias resolvidas mantendo medidas mais diretas (propor√ß√µes > dist√¢ncias, DEPREL > UPOS quando correlacionados).

## Interpreta√ß√£o Simplificada

Eliminamos mais da metade das m√©tricas porque eram redundantes, vazias, ou mediam constru√ß√µes rar√≠ssimas. Mantivemos apenas as medidas essenciais e interpret√°veis que realmente caracterizam estilo: diversidade vocabular, comprimento de senten√ßas, tipos de palavras (substantivos, verbos, etc.), e rela√ß√µes sint√°ticas principais (sujeito, objeto, modificadores).

## Implica√ß√µes Lingu√≠sticas

O conjunto final equilibra **cobertura** (captura m√∫ltiplas dimens√µes estil√≠sticas) e **interpretabilidade** (todas as m√©tricas t√™m significado lingu√≠stico claro). L√©xicas capturam superficie textual (vocabul√°rio, tamanho). UPOS capturam classes gramaticais (densidade nominal/verbal). DEPREL capturam estrutura sint√°tica (subordina√ß√£o, modifica√ß√£o). MDD captura complexidade global. Juntas, formam perfil estilom√©trico abrangente.
"""

report_file = OUTPUT_DIR / "filtering_report.md"
report_file.write_text(report)
print(f"   ‚úì Relat√≥rio salvo em: {report_file.relative_to(BASE_DIR)}")

print("\n" + "=" * 70)
print("‚úÖ FILTRAGEM CONCLU√çDA")
print("=" * 70)
print(f"\nüìä M√©tricas finais: {len(metrics_to_keep)} (redu√ß√£o de {(len(metric_cols) - len(metrics_to_keep))/len(metric_cols)*100:.1f}%)")
print(f"\nOutputs em: {OUTPUT_DIR.relative_to(BASE_DIR)}/")
print(f"  ‚Ä¢ all_texts_filtered.csv")
print(f"  ‚Ä¢ original_filtered.csv")
print(f"  ‚Ä¢ baseline_filtered.csv")
print(f"  ‚Ä¢ prompt_steering_filtered.csv")
print(f"  ‚Ä¢ activation_steering_filtered.csv")
print(f"  ‚Ä¢ filtering_report.md")
print()
