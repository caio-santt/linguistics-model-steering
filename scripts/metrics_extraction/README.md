# Sistema de ExtraÃ§Ã£o de MÃ©tricas EstilomÃ©tricas

Este diretÃ³rio contÃ©m o sistema completo para extraÃ§Ã£o de mÃ©tricas lÃ©xicas e sintÃ¡ticas dos textos originais e gerados.

## ğŸ“‹ Estrutura

```
scripts/metrics_extraction/
â”œâ”€â”€ basic_metrics.py           # MÃ©tricas lÃ©xicas (TTR, n-gramas, comprimentos)
â”œâ”€â”€ syntactic_metrics.py       # MÃ©tricas sintÃ¡ticas (UDPipe)
â”œâ”€â”€ windowed_analysis.py       # AnÃ¡lise temporal (divisÃ£o em janelas)
â”œâ”€â”€ extract_all_metrics.py     # Script principal (orquestra tudo)
â””â”€â”€ README.md                  # Esta documentaÃ§Ã£o

metrics/                        # Resultados (criado apÃ³s execuÃ§Ã£o)
â”œâ”€â”€ full_text/
â”‚   â”œâ”€â”€ individual/            # MÃ©tricas por texto
â”‚   â”‚   â”œâ”€â”€ all_texts.csv
â”‚   â”‚   â”œâ”€â”€ original.csv
â”‚   â”‚   â”œâ”€â”€ baseline.csv
â”‚   â”‚   â”œâ”€â”€ prompt_steering.csv
â”‚   â”‚   â””â”€â”€ activation_steering.csv
â”‚   â””â”€â”€ summary/               # MÃ©dias agregadas
â”‚       â”œâ”€â”€ by_author.csv
â”‚       â””â”€â”€ by_condition.csv
â”œâ”€â”€ windowed/                  # AnÃ¡lise temporal
â”‚   â””â”€â”€ lexical_windowed.csv
â””â”€â”€ udpipe_output/             # Arquivos CoNLL-U (intermediÃ¡rios)
```

## ğŸš€ Uso RÃ¡pido

### InstalaÃ§Ã£o de dependÃªncias

```bash
# No diretÃ³rio raiz do projeto
pip install pandas numpy nltk tqdm
```

### ExecuÃ§Ã£o completa

```bash
cd scripts/metrics_extraction

# ExtraÃ§Ã£o completa (full text + windowed)
python extract_all_metrics.py

# Apenas full text (pular windowed)
python extract_all_metrics.py --skip-windowed

# Customizar threshold de tokens mÃ­nimos para windowed
python extract_all_metrics.py --min-tokens 150
```

### ParÃ¢metros

- `--data-dir`: DiretÃ³rio com pasta `data/` (padrÃ£o: diretÃ³rio atual)
- `--output-dir`: DiretÃ³rio de saÃ­da (padrÃ£o: `metrics/`)
- `--skip-windowed`: Pular anÃ¡lise temporal
- `--min-tokens`: MÃ­nimo de tokens para anÃ¡lise windowed (padrÃ£o: 100)

## ğŸ“Š MÃ©tricas Calculadas

### MÃ©tricas LÃ©xicas (8 mÃ©tricas)

**Calculadas por:** `BasicMetrics`

1. **ttr** - Type-Token Ratio (diversidade lexical)
2. **tokens_per_sentence_mean** - MÃ©dia de tokens por sentenÃ§a
3. **chars_per_token_mean** - MÃ©dia de caracteres por token
4. **n_unique_unigrams** - NÃºmero de unigramas Ãºnicos
5. **n_unique_bigrams** - NÃºmero de bigramas Ãºnicos
6. **n_repeated_bigrams** - NÃºmero de bigramas repetidos
7. **n_unique_trigrams** - NÃºmero de trigramas Ãºnicos
8. **n_repeated_trigrams** - NÃºmero de trigramas repetidos

**ObservaÃ§Ãµes:**
- N-gramas calculados apÃ³s lematizaÃ§Ã£o (EN) ou stemming (PT)
- TTR calculado no texto original (sem normalizaÃ§Ã£o)
- Usa NLTK para tokenizaÃ§Ã£o e processamento

### MÃ©tricas SintÃ¡ticas (~218 mÃ©tricas)

**Calculadas por:** `SyntacticMetrics` (via UDPipe API)

1. **mean_dependency_distance** - DistÃ¢ncia mÃ©dia de dependÃªncia sintÃ¡tica

2. **RelaÃ§Ãµes DEPREL** (para cada relaÃ§Ã£o encontrada):
   - `DEPREL_{relaÃ§Ã£o}_prop` - ProporÃ§Ã£o da relaÃ§Ã£o
   - `DEPREL_{relaÃ§Ã£o}_md` - DistÃ¢ncia mÃ©dia
   - `DEPREL_count_{relaÃ§Ã£o}` - Contagem absoluta
   
   Exemplos: nsubj, obj, advmod, nmod, obl, etc.

3. **Tags UPOS** (para cada tag encontrada):
   - `UPOS_{tag}_prop` - ProporÃ§Ã£o da tag
   - `UPOS_{tag}_md` - DistÃ¢ncia mÃ©dia
   - `UPOS_count_{tag}` - Contagem absoluta
   
   Exemplos: NOUN, VERB, ADJ, ADV, etc.

**ObservaÃ§Ãµes:**
- Usa modelos Universal Dependencies v2.12
- PT: `portuguese-petrogold`
- EN: `english-gum`
- Requer conexÃ£o com API UDPipe
- Gera arquivos CoNLL-U intermediÃ¡rios

## ğŸ” AnÃ¡lise Temporal (Windowed)

### MÃ©tricas LÃ©xicas Windowed

**ConfiguraÃ§Ã£o:**
- NÃºmero de janelas: **5** (fixo)
- DivisÃ£o: Por tokens simples
- Tamanho: Adaptativo (total_tokens / 5)
- MÃ­nimo de tokens: 100 (configurÃ¡vel)

**PosiÃ§Ãµes das janelas:**
- Janela 0: 0-20% do texto (inÃ­cio)
- Janela 1: 20-40%
- Janela 2: 40-60% (meio)
- Janela 3: 60-80%
- Janela 4: 80-100% (fim)

**Uso:** Detectar decaimento estilÃ­stico ao longo da geraÃ§Ã£o.

### Filtragem de Textos AnÃ´malos

**CritÃ©rio:** Textos com < 100 tokens sÃ£o excluÃ­dos da anÃ¡lise windowed.

**RazÃ£o:** Janelas de ~20 tokens sÃ£o estatisticamente inviÃ¡veis (alta variÃ¢ncia, contexto insuficiente).

**Impacto esperado:**
- ~2 textos excluÃ­dos (0.5% do total)
- AnÃ¡lise full text preserva TODOS os textos
- Documentado em `metrics/windowed/excluded_texts.log` (se houver)

## ğŸ› ï¸ Arquitetura

### Modularidade

Cada mÃ³dulo Ã© independente e pode ser usado separadamente:

```python
# Apenas mÃ©tricas lÃ©xicas
from basic_metrics import BasicMetrics

text = "Your text here..."
metrics = BasicMetrics(text, lang='eng')
results = metrics.run()
print(results['ttr'])

# Apenas mÃ©tricas sintÃ¡ticas
from syntactic_metrics import SyntacticMetrics

metrics = SyntacticMetrics(text, lang='eng', text_id='example')
results = metrics.run()
print(results['mean_dependency_distance'])

# AnÃ¡lise em janelas
from windowed_analysis import WindowedAnalysis

wa = WindowedAnalysis(text, lang='eng', n_windows=5)
windows = wa.create_windows()

for window in windows:
    print(f"Window {window['idx']}: {window['n_tokens']} tokens")
    # Processar janela...
```

### Robustez

- **Fallbacks:** Se recursos NLTK nÃ£o disponÃ­veis, usa tokenizaÃ§Ã£o simples
- **Tratamento de erros:** Falhas individuais nÃ£o quebram pipeline completo
- **ValidaÃ§Ã£o:** Textos muito curtos sÃ£o flaggados
- **Progress bars:** Feedback visual via tqdm

## ğŸ“ˆ Outputs Esperados

### Full Text Individual

**Arquivo:** `metrics/full_text/individual/all_texts.csv`

**Linhas:** 600 (60 originais + 540 gerados)

**Colunas:**
- Metadados: text_id, author, title, sample_idx, rep, condition, lang
- MÃ©tricas: basic_*, synt_*

### Full Text Summary

**Arquivos:** 
- `by_author.csv` - MÃ©dias por autor (4 linhas)
- `by_condition.csv` - MÃ©dias por condiÃ§Ã£o (4 linhas: original + 3 geradas)

**Uso:** ComparaÃ§Ãµes rÃ¡pidas entre autores/condiÃ§Ãµes

### Windowed Lexical

**Arquivo:** `metrics/windowed/lexical_windowed.csv`

**Linhas:** ~2990 (598 textos vÃ¡lidos Ã— 5 janelas)

**Colunas:**
- Metadados: text_id, author, condition, window_idx, window_position, window_n_tokens
- MÃ©tricas: ttr, tokens_per_sentence_mean, etc. (8 mÃ©tricas)

**Uso:** AnÃ¡lise de decaimento temporal

## â±ï¸ Tempo de ExecuÃ§Ã£o Estimado

- **Full text lÃ©xicas:** ~10-15 minutos (600 textos)
- **Full text sintÃ¡ticas:** ~6-8 horas (600 chamadas API Ã— 30-40s cada)
- **Windowed lÃ©xicas:** ~1-2 horas (3000 janelas)

**Total estimado:** 7-11 horas (principalmente devido Ã  API UDPipe)

**Dicas:**
- Executar em horÃ¡rios de menor uso da API
- Considerar cache de resultados intermediÃ¡rios
- ComeÃ§ar com `--skip-windowed` para testar pipeline

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro: NLTK resources not found

```bash
python -c "import nltk; nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('wordnet'); nltk.download('omw-1.4'); nltk.download('rslp')"
```

### Erro: UDPipe API timeout

- API pode estar sobrecarregada
- Tentar novamente mais tarde
- Considerar instalar UDPipe localmente

### MÃ©tricas vazias (NaN)

- Verificar formato do texto de entrada
- Verificar logs de erro no console
- Textos muito curtos podem gerar NaN para algumas mÃ©tricas

## ğŸ“ Notas de ImplementaÃ§Ã£o

### DecisÃµes MetodolÃ³gicas

1. **DivisÃ£o de janelas para sintÃ¡ticas:** 
   - Deve respeitar limites de sentenÃ§a (nÃ£o quebrar Ã¡rvore de dependÃªncia)
   - Implementado em `windowed_analysis.py` com `respect_sentences=True`
   - Por enquanto, apenas lÃ©xicas implementadas no pipeline principal

2. **Threshold de 100 tokens:**
   - Baseado em anÃ¡lise empÃ­rica do dataset
   - Exclui apenas 2 textos anÃ´malos (~0.5%)
   - DocumentaÃ§Ã£o completa em `ANALISE_METRICAS_ORIGINAIS.md`

3. **LematizaÃ§Ã£o vs Stemming:**
   - PT: RSLPStemmer (stemming)
   - EN: WordNetLemmatizer (lematizaÃ§Ã£o)
   - Aplicado antes de calcular n-gramas

## ğŸ”® PrÃ³ximos Passos

1. âœ… Implementar extraÃ§Ã£o full text
2. âœ… Implementar windowed lÃ©xicas
3. â³ Implementar windowed sintÃ¡ticas (opcional)
4. â³ Adicionar anÃ¡lise estatÃ­stica (variÃ¢ncia, consistÃªncia)
5. â³ Gerar visualizaÃ§Ãµes
6. â³ AnÃ¡lise de RQ1 e RQ2

## ğŸ“š ReferÃªncias

- **UDPipe:** http://ufal.mff.cuni.cz/udpipe
- **Universal Dependencies:** https://universaldependencies.org/
- **NLTK:** https://www.nltk.org/
