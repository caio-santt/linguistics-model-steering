Aprendizado ou apredizagem por reforço ( AR ) é uma área interdisciplinar de aprendizado de máquina e controle ótimo que se preocupa com a forma como um agente inteligente deve tomar ações em um ambiente dinâmico para maximizar um sinal de recompensa . É um dos três paradigmas básicos de aprendizado de máquina , juntamente com o aprendizado supervisionado e o aprendizado não supervisionado . O Q-learning , em sua forma mais simples , armazena dados em tabelas . Essa abordagem se torna inviável à medida que o número de estados/ações aumenta ( por exemplo , se o espaço de estados ou o espaço de ações fosse contínuo ) , pois a probabilidade do agente visitar um estado específico e executar uma ação específica diminui . O aprendizado por reforço difere do aprendizado supervisionado por não precisar que pares de entrada-saída rotulados sejam apresentados e por não precisar que ações subótimas sejam explicitamente corrigidas . Em vez disso , o foco está em encontrar um equilíbrio entre a exploração ( de território desconhecido ) e a exploração ( do conhecimento atual ) com o objetivo de maximizar a recompensa cumulativa ( cujo feedback pode ser incompleto ou atrasado ) . [ 1 ] O ambiente é normalmente declarado na forma de um processo de decisão de Markov ( PDM ) , já que muitos algoritmos de aprendizagem por reforço usam técnicas de programação dinâmica . [ 2 ] A principal diferença entre os métodos clássicos de programação dinâmica e os algoritmos de aprendizagem por reforço é que estes últimos não pressupõem o conhecimento de um modelo matemático exato do processo de decisão de Markov e têm como alvo grandes PDMs onde os métodos exatos se tornam inviáveis . [ 3 ] Princípios Devido à sua generalidade , o aprendizado por reforço é estudado em muitas disciplinas , como teoria dos jogos , teoria de controle , pesquisa operacional , teoria da informação , otimização baseada em simulação , sistemas multiagente , inteligência de enxame e estatística . Na pesquisa operacional e na literatura de controle , o AR é chamado de programação dinâmica aproximada ou programação neuro-dinâmica . Os problemas de interesse em AR também são estudados na teoria de controle ótimo , que se preocupa principalmente com a existência e caracterização de soluções ótimas e algoritmos para seu cálculo exato , e menos com aprendizado ou aproximação ( particularmente na ausência de um modelo matemático do ambiente ) . O aprendizado por reforço básico é modelado como um processo de decisão de Markov : - Um conjunto de estados do ambiente e do agente ( o espaço de estados ) , S ; - Um conjunto de ações ( o espaço de ações ) , A , do agente ; - Pa ( s , s′ ) = Pr ( St+1 = s′ | St = s , At = a ) , a probabilidade de transição ( no tempo t ) de estado s para estado s′ sob