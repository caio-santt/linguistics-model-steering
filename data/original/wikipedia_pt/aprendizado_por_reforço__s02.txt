negativos e interpretar prazer e consumo de alimentos como reforços positivos . Em algumas circunstâncias , animais aprendem a adotar comportamentos que otimizam essas recompensas , sugerindo que animais são capazes de aprendizado por reforço . [ 4 ] [ 5 ] Um agente básico de aprendizado por reforço interage com seu ambiente em passos de tempo discretos . A cada passo de tempo t , o agente recebe o estado atual St e a recompensa Rt . Em seguida , escolhe uma ação At dentre as ações disponíveis , que então é enviada ao ambiente . O ambiente passa para um novo estado St+1 e a recompensa Rt+1 associada à transição ( St , At , St+1 ) é determinada . O objetivo de um agente de aprendizado por reforço é aprender uma política : π : S × A → [ 0,1 ] , π ( s , a ) = Pr ( At = a | St = s ) que maximize a recompensa acumulada esperada . Formular o problema como um processo de decisão de Markov pressupõe que o agente observa diretamente o estado atual do ambiente ; nesse caso , diz-se que o problema tem observabilidade completa . Se o agente só tem acesso a um subconjunto de estados ou se os estados observados são corrompidos por ruído , o agente tem observabilidade parcial , e formalmente o problema deve ser definido como um processo de decisão de Markov parcialmente observável . Em ambos os casos , o conjunto de ações disponíveis ao agente pode ser restringido . Por exemplo , o estado de um saldo bancário pode ser restrito a ser positivo ; se o valor atual do estado é 3 e a transição de estado tenta reduzir o valor em 4 , essa transição não será permitida . Quando o desempenho do agente é comparado ao de um agente que atua de modo ótimo , a diferença de desempenho resulta no conceito de arrependimento ( regret ) . Para agir de forma quase ótima , o agente deve raciocinar sobre as consequências de longo prazo de suas ações ( isto é , maximizar recompensas futuras ) , embora a recompensa imediata associada possa ser negativa . Assim , o aprendizado por reforço é particularmente adequado para problemas que envolvem a troca entre recompensas de longo e curto prazo . Ele já foi aplicado com sucesso a diversos problemas , incluindo armazenamento de energia , [ 6 ] controle de robôs , [ 7 ] geradores fotovoltaicos , [ 8 ] backgammon , damas , [ 9 ] Go ( AlphaGo ) e sistemas de direção autônoma . [ 10 ] Dois elementos tornam o aprendizado por reforço poderoso : o uso de amostras para otimizar desempenho e o uso de aproximação de função para lidar com ambientes grandes . Graças a esses dois componentes , o AR pode ser usado em ambientes grandes nas seguintes situações : - Um modelo do ambiente é