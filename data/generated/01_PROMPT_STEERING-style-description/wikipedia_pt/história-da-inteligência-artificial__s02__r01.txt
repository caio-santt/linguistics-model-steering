Na década de 1980, a pesquisa em inteligência artificial recebeu financiamento significativo da Agência de Projetos de Pesquisas Avançadas sobre Defesa (DARPA), nos Estados Unidos, e do Projeto da Quinta Geração, no Japão. Esse investimento impulsionou a criação de sistemas especialistas, que buscavam replicar o conhecimento de humanos em domínios específicos. Projetos como o XCON, que configurava computadores VAX, mostravam que máquinas poderiam ajudar em tarefas complexas. O XCON cresceu rapidamente, guiando decisões de montagem de hardware. Assim, a IA começou a ganhar credibilidade prática.

No mesmo período, pesquisadores no MIT e na Stanford desenvolveram a base de dados CYC, que tentava codificar todo o conhecimento comum em regras lógicas. CYC expandiu lentamente, mas sua ambição era clara: criar um universo de fatos que máquinas pudessem consultar. Enquanto isso, o mercado de software começou a valorizar sistemas que simulavam especialistas humanos. Empresas investiam em consultoria, e consultores de IA se tornavam prestigiados. A percepção pública de IA mudou: de um campo teórico para um recurso comercial.

Entretanto, a expansão descontrolada trouxe problemas. Sistemas especialistas eram caros de manter. Cada nova regra exigia trabalho manual. O custo aumentava, e a complexidade crescia. Além disso, a maioria das aplicações era limitada a contextos bem definidos. Quando os usuários tentavam usar os sistemas fora desses limites, o desempenho caía drasticamente. Assim, a confiança começou a diminuir.

Em 1987, a DARPA anunciou que reduziria o financiamento. O corte de recursos provocou o que ficou conhecido como o primeiro inverno da IA. Empresas que dependiam de projetos de IA fecharam, e pesquisadores se dispersaram. O entusiasmo diminuía, mas a curiosidade persistia. Enquanto alguns continuavam a trabalhar em inteligência baseada em regras, outros buscavam alternativas.

Na década de 1990, surgiram abordagens de aprendizado de máquina baseadas em estatística. Algoritmos de classificação e regressão ganharam atenção. A técnica de redes neurais artificiais, que havia sido negligenciada, começou a ressurgir. Os primeiros experimentos com backpropagation mostraram que redes podiam aprender padrões complexos. Esse resgate foi gradual, mas a promessa era forte: máquinas poderiam aprender a partir de dados, sem a necessidade de regras explícitas.

A década de 2000 trouxe avanços significativos. O aumento de poder computacional e a disponibilidade de grandes conjuntos de dados permitiram treinar redes profundas. O algoritmo de reconhecimento de imagens, o AlexNet, venceu o concurso ImageNet em 2012. Esse triunfo foi decisivo. As redes convolucionais mostraram que poderiam superar humanos em tarefas visuais. Assim, o campo se transformou novamente. A IA deixou de ser vista apenas como lógica simbólica e passou a ser vista como estatística e aprendizado.