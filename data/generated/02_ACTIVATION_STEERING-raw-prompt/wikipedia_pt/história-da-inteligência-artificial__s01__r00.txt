O sucesso inicial prosseguiu com a consolidação de projetos que buscavam, de maneira prática, a aplicação dos princípios teóricos em contextos industriais e militares. Em 1961, o projeto Shakey, liderado por Eric Thomas e David L. McCarthy, marcou a primeira tentativa de combinar percepção, planejamento e execução em um robô móvel. Shakey, equipado com sensores de visão e um pequeno computador de 8 bits, era capaz de mover-se em um ambiente doméstico, identificar obstáculos e executar tarefas simples como “pegar a maçã e levá‑la ao balcão”. Embora a máquina fosse lenta e limitada, o experimento demonstrou que a inteligência artificial não era apenas um conceito abstrato, mas uma disciplina capaz de criar sistemas que interagiam com o mundo físico.

Ao mesmo tempo, nas universidades de Stanford e MIT, surgiram os primeiros sistemas de processamento de linguagem natural. No laboratório de linguística computacional de Joseph Weizenbaum, em 1966, foi desenvolvido o programa ELIZA, que simulava um psicoterapeuta de Rogerian. Através de padrões de correspondência e respostas predefinidas, ELIZA conseguia manter conversas aparentemente coerentes, provocando debates éticos sobre a “inteligência” de máquinas que apenas imitavam a fala humana. Essa discussão inspirou pesquisadores a explorar algoritmos de aprendizado de máquina, levando à criação de redes neurais artificiais nas décadas seguintes.

A década de 1970 trouxe o advento de sistemas especialistas, que utilizavam bases de conhecimento estruturadas e regras de inferência para resolver problemas específicos. O sistema XCON, desenvolvido pela empresa Digital Equipment Corporation, era responsável por configurar computadores VAX a partir de requisitos do cliente. Em 1975, o programa MYCIN, criado por Edward Shortliffe na Universidade de Stanford, demonstrou que um sistema especialista poderia diagnosticar infecções bacterianas com precisão comparável a médicos especialistas. Esses exemplos mostraram que a IA podia superar humanos em tarefas restritas, mas também revelaram a dificuldade de generalizar conhecimento entre domínios diferentes.

Enquanto isso, a comunidade de robótica avançava em direção a sistemas mais autônomos. Em 1982, o robotica de armadura mecânica, chamado “PUMA 560”, foi usado em aplicações industriais para soldagem e montagem, empregando controle baseado em inteligência artificial para ajustar movimentos em tempo real. O mesmo ano, o grupo de pesquisa de Rodney Brooks no MIT introduziu a teoria da “inteligência embutida”, defendendo que a percepção e ação deveriam ser integradas em vez de separadas por uma camada de lógica de alto nível. Essa visão influenciou o design de robôs que aprendiam por meio de experimentação e interação com o ambiente, como o robotica “iRobot” que se tornaria popular na década de 1990.