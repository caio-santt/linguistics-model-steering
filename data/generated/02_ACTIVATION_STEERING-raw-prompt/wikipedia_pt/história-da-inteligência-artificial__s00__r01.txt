Alguns deles desenvolveram os primeiros protótipos de máquinas que, de forma rudimentar, imitavam processos cognitivos humanos. Em 1950, Alan Turing, por meio de seu artigo “Computing Machinery and Intelligence”, introduziu o que viria a ser conhecido como Teste de Turing, propondo que uma máquina poderia ser considerada inteligente se conseguisse enganar um observador humano em conversas escritas. Este marco teórico estabeleceu um critério prático para a avaliação de sistemas de IA, incentivando uma onda de pesquisas que buscavam construir agentes capazes de participar de diálogos complexos.

A década de 1950 também foi palco da criação do perceptron, por Frank Rosenblatt, um modelo de rede neural simples que utilizava um algoritmo de aprendizado supervisionado para classificar padrões binários. Embora o perceptron tenha sido limitado a tarefas lineares, ele abriu caminho para a posterior reavaliação das redes neurais, que, nas décadas seguintes, evoluiriam para arquiteturas profundas e recorrentes. Paralelamente, o trabalho de John McCarthy, Marvin Minsky, Allen Newell e Herbert A. Simon na Dartmouth Conference de 1956 consolidou a IA como disciplina acadêmica. Eles definiram a IA como “a ciência e engenharia de fazer máquinas inteligentes”, estabelecendo os primeiros programas de lógica simbólica, como o Logic Theorist, que demonstrou a capacidade de provar teoremas matemáticos de forma automática.

No final da década de 1950 e início dos anos 1960, a IA simbólica dominou o cenário científico. A lógica de primeira ordem e os sistemas de regras se tornaram as ferramentas principais para representar conhecimento. Programas como ELIZA, criado por Joseph Weizenbaum em 1964, simulavam uma conversa psicológica usando padrões de substituição, mostrando que a percepção de inteligência poderia ser manipulada por simples regras de processamento de linguagem natural. Entretanto, a complexidade dos problemas do mundo real rapidamente expôs limitações dos sistemas baseados em regras, levando à busca por abordagens mais robustas.

A década de 1970 testemunhou o auge dos sistemas especialistas, como o MYCIN, que aplicou regras de inferência para diagnosticar infecções bacterianas e sugerir tratamentos. Esses sistemas demonstraram que, com conhecimento codificado por especialistas humanos, uma máquina podia exceder a performance de profissionais em tarefas específicas. Contudo, a escalabilidade e a manutenção desses sistemas revelaram o “efeito de escassez de conhecimento”, onde a aquisição de conhecimento se tornava um gargalo, pois cada novo domínio exigia a intervenção de especialistas para gerar regras.

Ao longo dos anos 1980, a IA passou por um ressurgimento com a introdução de algoritmos de aprendizado de máquina mais sofisticados.