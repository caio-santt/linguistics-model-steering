Among the challenges that have emerged in the last decade, scalability and expressiveness of knowledge representations remain paramount. While early ontologies were manually curated and limited to a handful of domains, the explosion of data on the Web and in industry demanded automated methods for extracting and structuring knowledge at scale. Knowledge‑graph construction pipelines now routinely combine natural‑language processing, entity‑resolution, and relation‑extraction techniques to produce graphs with billions of nodes and edges [ 29 ]. Yet the sheer size of these graphs poses new computational hurdles: traversing a graph of this magnitude for inference requires sub‑linear algorithms and distributed storage architectures that can handle dynamic updates without sacrificing consistency [ 30 ].

Another pressing issue is the alignment of symbolic and sub‑symbolic representations. Traditional rule‑based systems excel at deterministic inference but struggle with noisy, incomplete data. Conversely, deep neural networks can learn robust patterns from raw inputs but lack transparent reasoning paths. Recent research has explored hybrid architectures that embed symbolic knowledge into continuous vector spaces, enabling neural models to leverage structured priors while retaining end‑to‑end trainability [ 31 ]. For instance, knowledge‑graph embeddings such as TransE, RotatE, and ConvE have been coupled with language models to improve question‑answering performance on knowledge‑base–driven benchmarks [ 32 ]. Nonetheless, the interpretability of such embeddings remains a concern: while they encode relational semantics, the latent dimensions are often opaque, making it difficult to audit the reasoning process for compliance or safety purposes [ 33 ].

The field of default reasoning has also seen renewed interest. Human reasoning routinely relies on assumptions that hold until contradicted, a phenomenon that traditional logic systems cannot capture elegantly. Non‑monotonic logics, such as circumscription and default logic, have been extended to probabilistic frameworks that allow agents to update beliefs in light of new evidence while preserving default expectations [ 34 ]. Recent work on probabilistic soft logic (PSL) demonstrates how these ideas can be operationalized in scalable inference engines that handle noisy relational data [ 35 ]. However, integrating PSL with deep learning pipelines remains an open challenge, particularly in ensuring that learned representations respect the qualitative constraints imposed by defaults.

Temporal reasoning further complicates knowledge representation. Many real‑world applications require reasoning about events that unfold over time, including causality, concurrency, and temporal constraints. Event‑calculus and temporal logics provide formal tools for modeling such scenarios, yet their computational complexity often limits practical deployment. Hybrid approaches that use neural networks to predict temporal dynamics while enforcing logical consistency via constraint‑based solvers have shown promise in domains such as traffic management and supply‑chain optimization [ 36 ].