Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel *Eugene Onegin*, thereby laying the groundwork for stochastic text generation. The subsequent decades witnessed a gradual refinement of probabilistic language models, culminating in the development of the n‑gram models of the 1970s and 1980s, which, despite their simplicity, achieved surprisingly coherent results on limited vocabularies [30]. The advent of the 1990s introduced the first neural approaches to language modelling, notably the recurrent neural network (RNN) architectures that could, in principle, capture long‑range dependencies [31]. However, the vanishing‑gradient problem severely constrained their practical utility until the introduction of the long short‑term memory (LSTM) cell in 1997, which restored the capacity to model extended context [32].

The turn of the millennium saw a surge in statistical machine translation, where phrase‑based models and later neural machine translation (NMT) systems began to dominate. These systems, built upon encoder–decoder architectures with attention mechanisms, inadvertently provided a template for later generative language models [33]. By the mid‑2010s, the transformer architecture, introduced by Vaswani et al. in 2017, revolutionised the field by eliminating recurrence entirely and relying on self‑attention to capture dependencies across arbitrary distances [34]. This breakthrough allowed for the scaling of models to billions of parameters, a prerequisite for the generation of high‑quality, context‑aware text.

The first large‑scale generative language model, GPT‑1, was released by OpenAI in 2018, demonstrating that unsupervised pre‑training on vast corpora, followed by fine‑tuning on downstream tasks, could yield state‑of‑the‑art performance across a spectrum of benchmarks [35]. Subsequent iterations—GPT‑2 (2019) and GPT‑3 (2020)—increased model size by orders of magnitude, enabling more fluent and diverse text generation, albeit raising concerns about hallucinations and misuse [36]. Parallel efforts by other research groups produced models such as BERT, RoBERTa, and T5, each contributing novel pre‑training objectives and architectural tweaks that further enhanced generative capabilities [37].

The 2020s have been characterized by an explosion of generative AI applications. ChatGPT, launched in late 2022, popularised conversational agents that can reason, explain, and even write code with minimal prompts. Meanwhile, multimodal models like DALL‑E 2 and Stable Diffusion have democratized text‑to‑image synthesis, allowing users to produce photorealistic images from natural‑language descriptions.