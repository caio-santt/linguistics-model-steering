A 2024 survey on the Chinese social app Soul reported that 76 % of users felt that AI‑generated content had become a staple of their daily interactions, citing chatbots, personalized recommendation engines, and automated content moderation as the primary drivers. The same study highlighted a growing trend toward “AI‑first” content creation, with 42 % of respondents admitting to using generative AI tools to draft posts, images, and even short videos before publishing them.

In the same month, the European Union’s Digital Services Act was amended to include a specific clause addressing generative AI. The amendment requires that any AI system deployed within the EU’s digital single market must disclose its training data provenance, model architecture, and a risk assessment report. The European Commission also announced a “Digital AI Observatory” to monitor compliance and provide an independent audit trail for high‑impact AI applications. Early reports suggest that the observatory will publish quarterly impact assessments, focusing on areas such as automated hiring, content moderation, and algorithmic bias mitigation.

Meanwhile, the United States saw a surge in federal funding for AI research and safety. The National Science Foundation announced a $1.2 billion initiative titled “Human‑Centric AI,” aimed at developing AI systems that can explain their reasoning, provide transparent confidence estimates, and be audited for fairness. The initiative will partner with industry, academia, and civil society groups to create a robust ecosystem for trustworthy AI. At the same time, the Federal Trade Commission released a draft guidance on “AI‑Powered Consumer Protection,” outlining new requirements for companies that sell AI‑driven products, including mandatory disclosure of algorithmic decision‑making processes and the right for consumers to request a human review.

In Asia, Japan’s Ministry of Economy, Trade and Industry rolled out a new “AI Innovation Promotion Plan” that earmarks ¥300 billion (approximately $2.2 billion) for research in multimodal AI, with a particular focus on integrating speech, vision, and sensor data for autonomous systems. The plan also includes incentives for startups that develop AI solutions for aging populations, such as robotic caregivers and personalized health monitoring systems.

South Korea, recognizing the strategic importance of AI, launched the “K‑AI 2030” roadmap. The roadmap sets a target of 30 % of the country’s GDP being generated by AI‑driven industries by 2030. To achieve this, the government is investing in nationwide AI labs, subsidizing AI education for K‑12 students, and creating a “AI Ethics Council” to oversee the deployment of AI in public services.

Across the globe, the United Nations released its first “Global AI Ethics and Governance Report.” The report, compiled by a coalition of UN agencies, highlights that while AI has the potential to accelerate development, it also poses significant risks related to privacy, surveillance, and inequality.