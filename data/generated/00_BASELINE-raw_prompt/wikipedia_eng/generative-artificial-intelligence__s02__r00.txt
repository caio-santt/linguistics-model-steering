A 2024 survey on the Chinese social app Soul reported that 72 % of its active users had interacted with an AI‑driven chatbot within the past month, citing content curation and mental‑health support as primary motivations. The same study highlighted a rapid increase in AI‑enabled features across domestic platforms, with 58 % of respondents noting that AI had improved the relevance of their feed, and 45 % claiming that AI tools had helped them discover new creators or communities. In contrast, a parallel survey conducted in the United States by Pew Research in the same year found that only 39 % of respondents had engaged with an AI chatbot, and just 27 % believed the technology had a positive impact on their daily lives. The disparity underscores a broader trend of regional variation in both adoption rates and perceived value of generative AI.

Beyond user‑level engagement, governmental policies have also diverged sharply. In 2024, the Chinese Ministry of Industry and Information Technology released a set of guidelines titled “Framework for the Development and Regulation of Artificial Intelligence,” which emphasized the dual role of AI as a driver of economic growth and a potential tool for social governance. The framework mandated that all AI‑based public services undergo a “trustworthiness” assessment, covering data security, algorithmic transparency, and bias mitigation. The guidelines also encouraged local governments to establish AI innovation hubs, offering tax incentives and subsidies to startups that integrated AI into public‑sector workflows.

Meanwhile, the European Union adopted the Artificial Intelligence Act in 2024, an extension of the 2021 draft regulation that classified AI systems into risk categories. The Act required high‑risk applications—such as those used in critical infrastructure, healthcare, and law enforcement—to undergo rigorous conformity assessments and maintain detailed documentation. The regulation also introduced a “right to explanation” clause, allowing individuals to request a clear and concise explanation of any AI‑driven decision that affected them. The EU’s approach has been widely praised for its emphasis on human oversight but criticized by some industry leaders for potentially stifling rapid innovation.

In the United States, the federal government took a more fragmented approach. The National Institute of Standards and Technology (NIST) issued a set of voluntary guidelines for AI risk management, focusing on transparency, accountability, and security. The guidelines were designed to be adaptable across industries, encouraging companies to develop internal governance frameworks rather than imposing a one‑size‑fits‑all regulatory model. However, the lack of a comprehensive federal law has left many states, notably California and New York, to draft their own AI regulations, creating a patchwork of requirements that can be challenging for multinational enterprises to navigate.

South Korea’s Ministry of Science and ICT released the “National AI Strategy 2024,” which outlined a three‑phase plan to integrate AI into manufacturing, healthcare, and education.