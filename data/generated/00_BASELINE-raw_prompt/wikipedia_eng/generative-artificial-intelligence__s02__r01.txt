In July 2024, OpenAI announced the public release of GPT‑4.5, a fine‑tuned iteration that incorporated reinforcement learning from human feedback (RLHF) on a dataset of 12 billion tokens, yielding a 3 % improvement in the MMLU benchmark over its predecessor. The update also introduced a “memory‑buffer” feature that allowed the model to retain context across multiple sessions, a capability that was highlighted in a series of demonstrations by the OpenAI research team. [63]

Around the same time, Baidu launched ERNIE 4.0, a multimodal model that fused text, speech, and video inputs. The model was engineered on a 200‑terabyte multimodal corpus curated from Chinese social media, news outlets, and open‑source datasets. ERNIE 4.0 achieved a 9 % relative gain on the Chinese version of the GLUE benchmark, and its open‑source release sparked a wave of academic papers exploring cross‑lingual transfer learning. [64]

The European Union, in response to the rapid proliferation of generative AI, adopted the “AI Act” in September 2024, establishing a risk‑based regulatory framework. The Act categorized AI systems into four tiers—minimal, limited, high, and unacceptable risk—requiring high‑risk systems such as those used in public administration or critical infrastructure to undergo conformity assessment and post‑market surveillance. The regulation also mandated “explainability” and “human‑in‑the‑loop” requirements for high‑risk applications. [65]

In the United States, the National AI Initiative Act was re‑authorized in October 2024, providing a $2.5 billion budget for federal research in AI safety, interpretability, and workforce development. The act also created the National AI Advisory Board, a body of academics, industry leaders, and civil society representatives tasked with reviewing emerging AI technologies and recommending policy adjustments. [66]

Amid these policy shifts, the tech community witnessed a surge in “AI‑for‑good” projects. The nonprofit OpenAI Foundation launched the “Ethical AI Lab” in November 2024, offering grants and technical mentorship to projects that aimed to address climate change, public health, and education. One notable initiative was the “Carbon‑Aware Chatbot” prototype, which integrated real‑time carbon‑footprint data into conversational AI, allowing users to estimate the environmental impact of their digital interactions. [67]

In December 2024, NVIDIA introduced the A100‑X GPU, a next‑generation accelerator optimized for large‑language‑model training. The chip featured 80 GB of HBM3 memory and a new tensor‑core architecture that reduced training time for GPT‑like models by 40 % compared to the A100‑PCIe.