O sucesso inicial prosseguiu com experimentos que, embora modesto, mostraram a viabilidade de máquinas que pudessem “pensar” em termos de regras e lógica. Em 1958, o engenheiro John McCarthy criou o LISP, uma linguagem de programação que se tornaria a ferramenta dominante para pesquisas em IA, graças à sua capacidade de manipular listas de forma recursiva e a sua sintaxe simbólica que refletia a estrutura do pensamento humano. Paralelamente, o algoritmo de busca em árvore de A* de Peter Hart, Nils Nilsson e Bertram Raphael, publicado em 1968, trouxe uma abordagem sistemática para problemas de planejamento e navegação, influenciando a criação de agentes autônomos.

Durante a década de 1970, a comunidade de IA começou a perceber a necessidade de modelos que não dependessem exclusivamente de regras fixas. A introdução dos perceptrons de Frank Rosenblatt em 1958, que só ganharam tração mais tarde, marcou o início da era dos “redes neurais” – sistemas que tentam imitar a plasticidade das sinapses cerebrais. Entretanto, o “Corte de 1974”, quando o pesquisador Marvin Minsky e Seymour Papert publicaram *Perceptrons*, apontou limitações fundamentais: perceptrons de camada única não podiam resolver problemas não linearmente separáveis. Essa crítica desencadeou um período de desânimo conhecido como “inverno da IA”, quando financiamentos escasseavam e o entusiasmo declinou.

Ainda assim, a década de 1980 trouxe a revolução dos sistemas especialistas. O MYCIN, desenvolvido na Universidade Stanford, foi um dos primeiros programas a demonstrar que um sistema baseado em regras pode diagnosticar infecções bacterianas com precisão comparável a médicos experientes. Ao mesmo tempo, o uso de redes bayesianas para modelar incertezas, popularizado por Judea Pearl, introduziu uma abordagem probabilística que se tornou padrão em muitos domínios, desde diagnóstico médico até sistemas de recomendação.

A década de 1990 foi marcada pela ascensão do aprendizado de máquina supervisionado. O algoritmo de Support Vector Machines (SVM), proposto por Vladimir Vapnik e seus colegas, trouxe a capacidade de encontrar fronteiras de decisão ótimas em espaços de alta dimensionalidade. Paralelamente, o advento de grandes bases de dados e a melhoria na capacidade computacional permitiram que pesquisas em visão computacional, como o algoritmo de Viola-Jones para detecção de faces em tempo real, se tornassem realidade. A competição de jogos, como o Deep Blue da IBM vencendo Garry Kasparov em 1997, demonstrou que máquinas poderiam superar os melhores humanos em tarefas altamente estruturadas.

Com a virada do milênio, a IA experimentou um renascimento impulsionado pelo aumento exponencial de dados e pela disponibilidade de GPUs para processamento paralelo.