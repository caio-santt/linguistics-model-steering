# ğŸ“Š AnÃ¡lise: Baseline vs Original

## ğŸ¯ Objetivo
Comparar textos gerados com **prompt bruto (baseline)** aos textos **originais** dos autores, identificando como a geraÃ§Ã£o sem steering afeta as caracterÃ­sticas estilÃ­sticas.

## ğŸ“ Estrutura de Dados
- **Original**: 60 textos (15 por autor)
- **Baseline**: 180 textos (45 por autor)
  - Estrutura: 3 samples Ã— 3 repetiÃ§Ãµes Ã— 15 textos = 45 por autor
  - Design balanceado para robustez estatÃ­stica

---

## ğŸ” Descobertas Principais

### 1. **Baseline como Regularizador EstilÃ­stico**

O modelo LLM atua como um **"regularizador estilÃ­stico"**, empurrando estilos extremos em direÃ§Ã£o ao centro:

#### ğŸ“ **Comprimento de SentenÃ§a**
| Autor | Original | Baseline | MudanÃ§a | InterpretaÃ§Ã£o |
|-------|----------|----------|---------|---------------|
| **Lispector** | 11.14 palavras | 25.59 palavras | **+129.7%** | Perdeu simplicidade distintiva |
| **Woolf** | 23.13 palavras | 27.71 palavras | +19.8% | Aumentou ligeiramente |
| **Wikipedia PT** | 24.36 palavras | 26.73 palavras | +9.7% | MudanÃ§a mÃ­nima |
| **Wikipedia EN** | 27.37 palavras | 27.09 palavras | -1.0% | Praticamente estÃ¡vel |

**ğŸ’¡ Insight**: Lispector tinha o estilo **mais distinto** (sentenÃ§as curtas). O baseline a **homogeneizou**, aproximando-a dos demais.

---

#### ğŸ—£ï¸ **Densidade Pronominal (PRON)**
| Autor | Original | Baseline | MudanÃ§a | InterpretaÃ§Ã£o |
|-------|----------|----------|---------|---------------|
| **Woolf** | 0.121 | 0.095 | **-21.1%** | Perdeu intensidade pronominal |
| **Wikipedia EN** | 0.076 | 0.062 | -18.4% | Reduziu uso de pronomes |
| **Lispector** | 0.067 | 0.099 | **+48.1%** | Aumentou dramaticamente |
| **Wikipedia PT** | 0.057 | 0.067 | +17.5% | Aumento moderado |

**Amplitude entre extremos**:
- Original: 6.22Ã— (Woolf/Wikipedia PT)
- Baseline: 4.61Ã— (Woolf/Lispector)

**ğŸ’¡ Insight**: O baseline **reduziu a diferenciaÃ§Ã£o** entre autores, convergindo para um uso pronominal intermediÃ¡rio.

---

### 2. **Deslocamento no EspaÃ§o PCA**

Treinamos um PCA nos textos **originais** e projetamos os textos **baseline** no mesmo espaÃ§o:

#### ğŸ¯ **VariÃ¢ncia Explicada**
- **PC1** (Complexidade SintÃ¡tica): 24.07%
- **PC2** (Verbal vs Nominal): 18.76%
- **PC3** (Diversidade Textual): 9.42%
- **Total (3 PCs)**: 52.25%

#### ğŸ“ **DistÃ¢ncias de Deslocamento**
| Autor | DistÃ¢ncia Total | InterpretaÃ§Ã£o |
|-------|-----------------|---------------|
| **Woolf** | **4.39** | Maior deslocamento - estilo muito afetado |
| **Wikipedia EN** | 1.68 | Deslocamento moderado |
| **Lispector** | 1.65 | Deslocamento moderado |
| **Wikipedia PT** | 0.93 | Menor deslocamento - estilo mais preservado |

**ğŸ’¡ Insight**: Autores com estilos **mais complexos** (Woolf) foram os **mais afetados** pelo baseline.

---

### 3. **DecomposiÃ§Ã£o Dimensional do Deslocamento**

#### ğŸ”¬ **Componentes do Movimento**

| Autor | Î”PC1 (Complexidade) | Î”PC2 (Verbal/Nominal) | Componente Dominante |
|-------|---------------------|----------------------|---------------------|
| **Woolf** | **-4.23** (96.3% do total) | -1.18 | **PC1**: SimplificaÃ§Ã£o massiva |
| **Wikipedia EN** | -1.10 | **-1.27** (75.5%) | **PC2**: NominalizaÃ§Ã£o |
| **Lispector** | **+1.07** âœ… | -1.25 (76.1%) | **PC2**: NominalizaÃ§Ã£o |
| **Wikipedia PT** | -0.40 | **+0.84** âœ… (90.1%) | **PC2**: VerbalizaÃ§Ã£o (Ãºnica!) |

#### ğŸ“Š **PadrÃµes Identificados**

**A. DireÃ§Ã£o das MudanÃ§as**:
- **SimplificaÃ§Ã£o** (PC1 â†“): 3/4 autores (Woolf, Wikipedia EN, Wikipedia PT)
- **ComplexificaÃ§Ã£o** (PC1 â†‘): 1/4 autor (**Lispector** - Ãºnica!)
- **NominalizaÃ§Ã£o** (PC2 â†“): 3/4 autores (Woolf, Wikipedia EN, Lispector)
- **VerbalizaÃ§Ã£o** (PC2 â†‘): 1/4 autor (**Wikipedia PT** - Ãºnica!)

**B. InterpretaÃ§Ãµes**:

ğŸ”´ **WOOLF**:
- **-4.23 em PC1**: Perdeu drasticamente complexidade sintÃ¡tica
- **96.3% da mudanÃ§a foi em complexidade**
- Ficou mais simples E mais nominal
- **Maior impacto de todos os autores**

ğŸŸ¢ **LISPECTOR** (comportamento oposto!):
- **+1.07 em PC1**: GANHOU complexidade (Ãºnica!)
- Partiu de muito simples (11 palavras/sentenÃ§a) â†’ baseline adicionou complexidade
- Mas perdeu verbalidade (-1.25), como os demais

ğŸ”µ **WIKIPEDIA PT**:
- **+0.84 em PC2**: GANHOU verbalidade (Ãºnica!)
- Menor deslocamento total (0.93)
- Baseline preservou relativamente bem suas caracterÃ­sticas

ğŸŸ¡ **WIKIPEDIA EN**:
- MudanÃ§as equilibradas em ambas dimensÃµes
- SimplificaÃ§Ã£o + NominalizaÃ§Ã£o moderadas

---

### 4. **Perda de Diversidade (PC3)**

**Todos os autores** se moveram negativamente em PC3 (Diversidade):

| Autor | PC3 Original | PC3 Baseline | Î”PC3 | InterpretaÃ§Ã£o |
|-------|--------------|--------------|------|---------------|
| **Woolf** | -1.32 | -3.83 | **-2.51** | Mais repetitivo |
| **Wikipedia EN** | -1.36 | -3.71 | **-2.35** | Mais repetitivo |
| **Lispector** | +2.02 | +0.59 | **-1.43** | Perdeu originalidade |
| **Wikipedia PT** | +0.67 | +0.00 | **-0.66** | Convergiu para neutro |

**ğŸ’¡ Insight**: Baseline **reduz originalidade** e **aumenta padrÃµes repetitivos** em TODOS os autores.

---

### 5. **ReversÃ£o de PadrÃµes de N-gramas**

Descobrimos um padrÃ£o **oposto** entre autores Ãºnicos e repetitivos:

#### ğŸ“ˆ **Trigramas Repetidos**
| Autor | Original | Baseline | MudanÃ§a |
|-------|----------|----------|---------|
| **Lispector** | 15 | 41 | **+167%** â¬†ï¸ |
| **Woolf** | 87 | 28 | **-68%** â¬‡ï¸ |
| **Wikipedia EN** | 205 | 33 | **-84%** â¬‡ï¸ |

#### ğŸ“Š **Bigramas Repetidos**
| Autor | Original | Baseline | MudanÃ§a |
|-------|----------|----------|---------|
| **Lispector** | 82 | 130 | **+58%** â¬†ï¸ |
| **Woolf** | 210 | 120 | **-43%** â¬‡ï¸ |
| **Wikipedia EN** | 360 | 109 | **-70%** â¬‡ï¸ |

**ğŸ’¡ Insight Chave**: 
- **Lispector** (Ãºnica): Aumentou repetiÃ§Ãµes â†’ modelo adicionou padrÃµes
- **Woolf & Wikipedia**: Reduziram repetiÃ§Ãµes â†’ modelo diversificou

**HipÃ³tese**: O modelo possui um **"ponto de equilÃ­brio"** para repetiÃ§Ãµes:
- Autores **muito Ãºnicos** â†’ modelo adiciona repetiÃ§Ãµes (convergÃªncia)
- Autores **muito formulaicos** â†’ modelo remove repetiÃ§Ãµes (convergÃªncia)
- **Resultado**: Todos convergem para o centro

---

## ğŸ¨ VisualizaÃ§Ãµes Criadas

### 1. `01_key_metrics_comparison.png`
- ComparaÃ§Ã£o de 3 mÃ©tricas interpretÃ¡veis
- Barras com erro padrÃ£o
- Destaca mudanÃ§as percentuais

### 2. `02_pca_movement.png`
- Scatter plot: textos individuais no espaÃ§o PCA
- Setas de deslocamento: centro original â†’ centro baseline
- QuantificaÃ§Ã£o de distÃ¢ncias

### 3. `03_displacement_decomposition.png`
- **Esquerda**: Barras empilhadas (componentes PC1 + PC2)
- **Direita**: Barras horizontais (direÃ§Ã£o com sinais)
- Mostra contribuiÃ§Ã£o de cada dimensÃ£o

### 4. `04_displacement_profiles.png`
- **Esquerda**: Vetores no espaÃ§o (Î”PC1 Ã— Î”PC2)
- **Direita**: Radar chart (magnitude das mudanÃ§as)
- Identifica clusters de comportamento

---

## ğŸ“Š Dados Exportados

1. **`metric_changes.csv`**: MudanÃ§as percentuais nas mÃ©tricas-chave
2. **`pca_movement.csv`**: Coordenadas PCA e distÃ¢ncias
3. **`displacement_decomposition.csv`**: DecomposiÃ§Ã£o dimensional completa

---

## ğŸ§  ConclusÃµes

### âœ… HipÃ³tese Validada: **Baseline = Regularizador EstilÃ­stico**

1. **ConvergÃªncia para o Centro**: 
   - Estilos extremos (Lispector, Woolf) sÃ£o puxados para valores intermediÃ¡rios
   - ReduÃ§Ã£o de diferenciaÃ§Ã£o entre autores

2. **Perda de Complexidade (maioria)**:
   - 3/4 autores simplificaram sintaticamente
   - ExceÃ§Ã£o: Lispector ganhou complexidade (partiu de muito simples)

3. **TendÃªncia Ã  NominalizaÃ§Ã£o**:
   - 3/4 autores reduziram verbalidade
   - ExceÃ§Ã£o: Wikipedia PT aumentou verbalidade

4. **ReduÃ§Ã£o Universal de Diversidade**:
   - PC3 negativo para TODOS
   - Baseline aumenta repetiÃ§Ãµes ou reduz originalidade

5. **ReversÃ£o de N-gramas**:
   - Autores Ãºnicos â†’ mais repetitivos
   - Autores formulaicos â†’ menos repetitivos
   - **EvidÃªncia de "ponto de equilÃ­brio" do modelo**

---

## ğŸš€ PrÃ³ximos Passos

1. **Comparar com Prompt Steering**: O steering consciente preserva melhor o estilo?
2. **Comparar com Activation Steering**: IntervenÃ§Ã£o nos activations Ã© mais eficaz?
3. **MÃ©tricas SintÃ¡ticas EspecÃ­ficas**: Analisar dependÃªncias e estruturas arbÃ³reas
4. **AnÃ¡lise Temporal**: MudanÃ§as ocorrem no inÃ­cio ou fim da geraÃ§Ã£o?
5. **Efeito do Sample**: Diferentes seed texts produzem padrÃµes diferentes?

---

## ğŸ“ Metodologia

- **Abordagem**: Incremental, levantando hipÃ³teses e respondendo individualmente
- **Ferramentas**: Python (pandas, sklearn, matplotlib, seaborn)
- **PCA**: Treinado em originais, baseline projetado no mesmo espaÃ§o
- **EstatÃ­sticas**: MÃ©dias, desvios padrÃ£o, coeficientes de variaÃ§Ã£o
- **VisualizaÃ§Ãµes**: 4 plots com mÃºltiplas perspectivas dos dados
