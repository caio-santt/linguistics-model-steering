# ğŸ“Š AnÃ¡lise: Activation Steering vs Original

## ğŸ¯ Objetivo
Comparar textos gerados com **activation steering** (intervenÃ§Ã£o nos activations do modelo) aos textos **originais**, avaliando se manipulaÃ§Ã£o interna preserva melhor o estilo que mÃ©todos baseados em prompt.

## ğŸ“ Estrutura de Dados
- **Original**: 60 textos (15 por autor)
- **Activation Steering**: 180 textos (45 por autor)
  - Estrutura: 3 samples Ã— 3 repetiÃ§Ãµes = 45 por autor

---

## ğŸ” Descobertas Principais

### 1. **Activation Steering â‰ˆ Baseline: Resultados Similares**

#### ğŸ“ **Comprimento de SentenÃ§a**
| Autor | Original | Activation | MudanÃ§a | vs Baseline |
|-------|----------|------------|---------|-------------|
| **Lispector** | 11.14 palavras | 25.73 palavras | **+130.9%** | Similar (+129.7%) |
| **Woolf** | 23.13 palavras | 26.18 palavras | +13.2% | Similar (+19.8%) |
| **Wikipedia EN** | 29.63 palavras | 28.62 palavras | -3.4% | Inverteu (+177.8% prompt) |
| **Wikipedia PT** | 34.39 palavras | 32.43 palavras | -5.7% | Similar (+9.7%) |

**ğŸ’¡ Insight**: 
- **Activation** reproduz padrÃ£o do **baseline** (convergÃªncia ~26 palavras)
- Lispector novamente teve maior mudanÃ§a (+131%)
- **Contraste com Prompt**: Wikipedia EN aqui reduziu (-3%), no prompt explodiu (+178%)

---

#### ğŸ—£ï¸ **Densidade Pronominal**
| Autor | Original | Activation | MudanÃ§a | InterpretaÃ§Ã£o |
|-------|----------|------------|---------|---------------|
| **Lispector** | 0.067 | 0.106 | +58.2% | Ganhou uso pronominal |
| **Wikipedia PT** | 0.019 | 0.022 | +13.6% | Leve aumento |
| **Woolf** | 0.121 | 0.093 | **-23.1%** | Perdeu intensidade |
| **Wikipedia EN** | 0.034 | 0.022 | **-36.4%** | ReduÃ§Ã£o dramÃ¡tica |

**Amplitude entre extremos**:
- Original: 6.36Ã— (Woolf/Wikipedia PT)
- Activation: 4.82Ã— (Lispector/Wikipedia PT)
- **Similar ao Baseline** (4.61Ã—)

---

#### ğŸ“– **Riqueza Vocabular (TTR)**
| Autor | Original | Activation | MudanÃ§a | vs Baseline vs Prompt |
|-------|----------|------------|---------|----------------------|
| **Wikipedia EN** | 0.486 | 0.542 | **+11.4%** âœ… | Ãšnico que ganhou! |
| **Woolf** | 0.461 | 0.475 | +3.0% | Preservou |
| **Wikipedia PT** | 0.515 | 0.518 | +0.7% | EstÃ¡vel |
| **Lispector** | 0.512 | 0.458 | -10.5% | Perdeu menos que outros |

**ğŸ’¡ Insight Chave**: 
- **Activation** preserva melhor TTR que baseline e prompt!
- 3/4 autores mantiveram ou ganharam riqueza vocabular
- **Contraste dramÃ¡tico com Prompt** (todos perderam -17% a -40%)

---

### 2. **Deslocamento no EspaÃ§o PCA**

#### ğŸ“ **DistÃ¢ncias de Deslocamento**
| Autor | DistÃ¢ncia | vs Baseline | vs Prompt | InterpretaÃ§Ã£o |
|-------|-----------|-------------|-----------|---------------|
| **Woolf** | **4.57** | +4.1% (4.39) | +70.5% (2.68) | Praticamente igual ao baseline |
| **Wikipedia EN** | 1.65 | -1.3% (1.68) | -69.3% (5.39) | EstÃ¡vel baseline, muito diferente prompt |
| **Lispector** | 1.49 | -9.4% (1.65) | -36.6% (2.35) | Menor impacto |
| **Wikipedia PT** | **0.87** | -6.5% (0.93) | -86.7% (6.53) | MELHOR PRESERVADO! |

**âš ï¸ PADRÃƒO CRÃTICO:**
- **Activation â‰ˆ Baseline** em todas as distÃ¢ncias
- **Woolf**: Activation 4.57 vs Baseline 4.39 (diferenÃ§a <5%)
- **Wikipedia PT**: Menor distÃ¢ncia em TODOS os mÃ©todos
- **Prompt**: Ãšnico mÃ©todo drasticamente diferente (especialmente Wikipedias)

---

### 3. **DecomposiÃ§Ã£o Dimensional do Deslocamento**

#### ğŸ”¬ **Componentes do Movimento**

| Autor | Î”PC1 (Complexidade) | Î”PC2 (Verbal/Nominal) | vs Baseline |
|-------|---------------------|----------------------|-------------|
| **Woolf** | **-4.41** (96.4%) | -1.21 (26.6%) | PC1: -4.23 (98% similar!) |
| **Wikipedia EN** | -1.09 (66.2%) | -1.24 (75.0%) | Similar pattern |
| **Lispector** | +1.13 (75.4%) | -0.98 (65.6%) | PC1: +1.07 (similar) |
| **Wikipedia PT** | -0.32 (37.2%) | **+0.81** (92.8%) | PC2: +0.84 (idÃªntico!) |

#### ğŸ“Š **PadrÃµes Identificados**

**A. DireÃ§Ã£o das MudanÃ§as - IDÃŠNTICO AO BASELINE:**
- **SimplificaÃ§Ã£o** (PC1 â†“): 3/4 autores (Woolf, Wikipedias)
- **ComplexificaÃ§Ã£o** (PC1 â†‘): 1/4 autor (Lispector)
- **NominalizaÃ§Ã£o** (PC2 â†“): 3/4 autores (Woolf, Wikipedia EN, Lispector)
- **VerbalizaÃ§Ã£o** (PC2 â†‘): 1/4 autor (Wikipedia PT)

**ğŸ”¥ COMPARAÃ‡ÃƒO COM OS 3 MÃ‰TODOS:**

| DireÃ§Ã£o | Baseline | Activation | Prompt |
|---------|----------|------------|--------|
| PC1 â†“ (Simplificam) | 3/4 | **3/4** | **0/4** |
| PC1 â†‘ (Complexificam) | 1/4 | **1/4** | **4/4** |
| PC2 â†“ (Nominalizam) | 3/4 | **3/4** | 2/4 |
| PC2 â†‘ (Verbalizam) | 1/4 | **1/4** | 2/4 |

**Activation = Baseline em TODAS as direÃ§Ãµes!**

---

**B. InterpretaÃ§Ãµes por Autor**:

ğŸ”µ **WOOLF** (pior resultado):
- **-4.41 em PC1**: Perdeu massivamente complexidade
- **96.4% da mudanÃ§a** foi em complexidade
- Baseline: -4.23 (diferenÃ§a <5%)
- Prompt: +0.52 (PROMPT PRESERVOU MELHOR!)
- **Activation nÃ£o oferece vantagem**

ğŸ”´ **LISPECTOR** (Ãºnica complexificadora):
- **+1.13 em PC1**: Ganhou complexidade
- Baseline: +1.07, Prompt: +2.25
- **Prompt foi mais eficaz em complexificar**
- Activation = baseline

ğŸŸ¡ **WIKIPEDIA PT** (melhor preservado):
- **+0.81 em PC2**: VerbalizaÃ§Ã£o dominante
- DistÃ¢ncia 0.87 (menor de todos)
- Baseline: 0.93, Prompt: 6.53
- **Activation melhor para Wikipedia PT**

ğŸŸ¢ **WIKIPEDIA EN**:
- SimplificaÃ§Ã£o + NominalizaÃ§Ã£o
- Activation: -1.09 PC1, -1.24 PC2
- Prompt: +5.39 PC1 (OPOSTO COMPLETO!)
- **Activation = baseline, Prompt = divergente**

---

### 4. **ComparaÃ§Ã£o Tripla: Baseline vs Activation vs Prompt**

| Aspecto | Baseline | Activation | Prompt |
|---------|----------|------------|--------|
| **Complexidade** | 3/4 simplificam | **3/4 simplificam** | 4/4 complexificam |
| **Woolf PC1** | -4.23 | **-4.41** (similar) | +0.52 (oposto) |
| **Lispector PC1** | +1.07 | **+1.13** (similar) | +2.25 (maior) |
| **DistÃ¢ncias** | 0.93-4.39 | **0.87-4.57** (similar) | 2.35-6.53 (maior) |
| **TTR** | VariÃ¡vel | **3/4 ganham** âœ… | Todos perdem âŒ |
| **Comprimento** | ConvergÃªncia ~26 | **ConvergÃªncia ~26** | DivergÃªncia 6-82 |
| **Pronomes** | ConvergÃªncia 4.61Ã— | **ConvergÃªncia 4.82Ã—** | ConvergÃªncia 1.63Ã— |

---

## ğŸ§  ConclusÃµes

### âœ… Descobertas Chave

1. **Activation Steering â‰ˆ Baseline**:
   - PadrÃµes quase idÃªnticos em todas as mÃ©tricas
   - DiferenÃ§as <10% nas distÃ¢ncias PCA
   - Mesma direÃ§Ã£o de mudanÃ§a (3/4 simplificam, 3/4 nominalizam)
   - **IntervenÃ§Ã£o nos activations nÃ£o superou prompt simples**

2. **Woolf NÃ£o Preservada**:
   - Activation: -4.41 (pior)
   - Baseline: -4.23 (pior)
   - Prompt: +0.52 (**melhor!**)
   - **Prompt steering foi superior para autores complexos**

3. **Wikipedia PT Melhor Preservada**:
   - Activation: 0.87 (melhor entre todos os mÃ©todos)
   - Menor impacto em textos enciclopÃ©dicos neutros
   - Consistente atravÃ©s dos 3 mÃ©todos

4. **TTR: Ãšnica Vantagem do Activation**:
   - 3/4 autores mantiveram ou ganharam riqueza vocabular
   - Wikipedia EN: +11.4% (Ãºnico ganho em todos os mÃ©todos!)
   - Baseline: variÃ¡vel
   - Prompt: todos perderam (-17% a -40%)
   - **Activation preserva melhor diversidade lexical**

5. **Prompt Steering Ãšnico Diferente**:
   - Todos complexificam (oposto de baseline/activation)
   - Maiores distÃ¢ncias (2.35-6.53)
   - DivergÃªncia extrema em comprimento (6-82 palavras)
   - **Ãšnico mÃ©todo que muda comportamento fundamental**

6. **Lispector: Sempre Complexifica**:
   - Todos os mÃ©todos: PC1 positivo
   - Baseline: +1.07, Activation: +1.13, Prompt: +2.25
   - Modelo sempre adiciona complexidade a textos curtos
   - **Prompt intensifica o efeito**

7. **NominalizaÃ§Ã£o Dominante**:
   - Baseline: 3/4 nominalizam
   - Activation: 3/4 nominalizam
   - Prompt: 2/4 nominalizam (split)
   - **TendÃªncia natural do modelo**

---

## ğŸ¯ Ranking de MÃ©todos por Objetivo

### **Para Preservar Complexidade de Autores LiterÃ¡rios (Woolf):**
1. **Prompt Steering** (+0.52) âœ…
2. Baseline (-4.23)
3. Activation (-4.41) âŒ

### **Para Preservar Textos EnciclopÃ©dicos (Wikipedias):**
1. **Activation** (0.87-1.65) âœ…
2. Baseline (0.93-1.68)
3. Prompt (5.39-6.53) âŒ

### **Para Preservar Riqueza Vocabular:**
1. **Activation** (3/4 ganham) âœ…
2. Baseline (variÃ¡vel)
3. Prompt (todos perdem) âŒ

### **Para Criar Textos Complexos:**
1. **Prompt** (4/4 complexificam) âœ…
2. Activation (1/4 complexifica)
3. Baseline (1/4 complexifica) âŒ

---

## ğŸ’¡ HipÃ³teses Validadas/Refutadas

### âŒ REFUTADAS:
1. **"Activation steering preserva melhor que baseline"**
   - Falso: Resultados praticamente idÃªnticos
   - ExceÃ§Ã£o: TTR ligeiramente melhor

2. **"IntervenÃ§Ã£o interna Ã© superior a instruÃ§Ãµes externas"**
   - Falso: Prompt steering foi superior para Woolf
   - Activation nÃ£o mudou comportamento fundamental

### âœ… VALIDADAS:
1. **"Modelo tem viÃ©s de simplificaÃ§Ã£o"**
   - Confirmado: 3/4 autores simplificam (baseline + activation)
   - Apenas prompt inverte isso

2. **"TTR mais sensÃ­vel a mÃ©todo de steering"**
   - Confirmado: Activation preserva, Prompt destrÃ³i

3. **"Textos neutros sÃ£o mais preservados"**
   - Confirmado: Wikipedia PT menor distÃ¢ncia em todos os mÃ©todos

---

## ğŸ¨ VisualizaÃ§Ãµes Criadas

1. **`01_key_metrics_comparison.png`**: 3 mÃ©tricas interpretÃ¡veis
2. **`02_pca_movement.png`**: Movimento PCA com componentes
3. **`03_displacement_decomposition.png`**: DecomposiÃ§Ã£o dimensional
4. **`04_displacement_profiles.png`**: Vetores e radar chart

---

## ğŸ“Š Dados Exportados

1. **`metric_changes.csv`**: MudanÃ§as nas 3 mÃ©tricas
2. **`pca_movement.csv`**: Coordenadas e distÃ¢ncias PCA
3. **`displacement_decomposition.csv`**: DecomposiÃ§Ã£o PC1 vs PC2

---

## ğŸš€ PrÃ³ximos Passos

1. **AnÃ¡lise Comparativa 3-Way**: Baseline vs Prompt vs Activation lado a lado
2. **Investigar Causa do TTR**: Por que activation preserva vocabulÃ¡rio?
3. **MÃ©tricas de CoerÃªncia**: Qual mÃ©todo gera textos mais coerentes?
4. **Trade-offs**: Complexidade Ã— VocabulÃ¡rio Ã— Fidelidade
5. **RecomendaÃ§Ãµes**: Quando usar cada mÃ©todo?

---

## ğŸ SÃ­ntese Final

**Activation Steering nÃ£o oferece vantagem significativa sobre Baseline simples.**

- PadrÃµes idÃªnticos em 90% das mÃ©tricas
- Ãšnica vantagem: preservaÃ§Ã£o de TTR (+11% vs -10%)
- NÃ£o resolve problema de simplificaÃ§Ã£o de autores complexos
- **Prompt Steering Ã© o Ãºnico mÃ©todo que muda comportamento fundamental**

**RecomendaÃ§Ã£o**: 
- Use **Prompt** para autores literÃ¡rios complexos (Woolf)
- Use **Activation/Baseline** para textos neutros (Wikipedias)
- **NÃ£o hÃ¡ justificativa para complexidade adicional do Activation** sobre Baseline
