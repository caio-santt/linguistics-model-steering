# Linguistics and Model Steering

AnÃ¡lise quantitativa de preservaÃ§Ã£o de estilo autoral em textos gerados por LLMs usando trÃªs tÃ©cnicas de steering: baseline prompting, prompt steering com descriÃ§Ãµes estilÃ­sticas, e activation steering via manipulaÃ§Ã£o de representaÃ§Ãµes internas.

## ğŸ“Š VisÃ£o Geral

Este projeto investiga como diferentes mÃ©todos de controle (steering) de modelos de linguagem afetam a preservaÃ§Ã£o de caracterÃ­sticas estilÃ­sticas autorais em textos gerados. Analisamos 600 textos atravÃ©s de 65 mÃ©tricas linguÃ­sticas filtradas, cobrindo dimensÃµes lÃ©xicas e sintÃ¡ticas.

**Principais achados:**
- Activation steering preserva melhor o estilo original (0.716) comparado a prompt steering (0.623)
- Baseline sofre decaimento temporal artificial (vocabulÃ¡rio esgota 16Ã— mais rÃ¡pido que originais)
- Activation steering Ã© significativamente mais consistente entre geraÃ§Ãµes (CV=0.189 vs 0.342 prompt)
- Nenhum mÃ©todo controla completamente estruturas sintÃ¡ticas profundas (subordinaÃ§Ã£o, apposiÃ§Ã£o)

## âš ï¸ Nota Importante: RepositÃ³rio Parcial

Este repositÃ³rio contÃ©m **apenas a anÃ¡lise linguÃ­stica** dos textos gerados. Os seguintes componentes **nÃ£o estÃ£o incluÃ­dos** e serÃ£o adicionados futuramente:

### Ausentes no RepositÃ³rio Atual:

1. **ğŸ“š Dataset Completo de Treinamento**
   - Textos literÃ¡rios usados para calcular vetores de steering (corpus de treinamento Lispector/Woolf)
   - Textos enciclopÃ©dicos usados como contrafactual (corpus completo Wikipedia)
   - Apenas os 60 prefixes de avaliaÃ§Ã£o estÃ£o incluÃ­dos em `data/original/`

2. **ğŸ§® Pipeline de CÃ¡lculo de Steering Vectors**
   - CÃ³digo para extraÃ§Ã£o de ativaÃ§Ãµes da camada 12
   - CÃ¡lculo de vetores contrafactuais (literÃ¡rio - enciclopÃ©dico)
   - Metodologia de aplicaÃ§Ã£o dos vetores durante geraÃ§Ã£o
   - Scripts de geraÃ§Ã£o dos 540 textos

3. **ğŸ“ Prompts de GeraÃ§Ã£o** âš ï¸ **CRÃTICO**
   - Prompt baseline (continuaÃ§Ã£o simples)
   - **Prompt steering com descriÃ§Ãµes estilomÃ©tricas detalhadas** (necessÃ¡rio para interpretar mÃ©tricas)
   - InstruÃ§Ãµes de temperatura, top-p, e outros hiperparÃ¢metros

**Status atual:** RepositÃ³rio focado em anÃ¡lise downstream. Pipeline upstream serÃ¡ documentado em breve.

## ğŸ“ Estrutura do Projeto

```
linguistics_and_model_steering/
â”œâ”€â”€ data/                          # Textos de entrada (60 originais + 540 gerados)
â”‚   â”œâ”€â”€ original/                  # 4 autores Ã— 15 samples cada
â”‚   â””â”€â”€ generated/                 # 3 mÃ©todos Ã— 3 repetiÃ§Ãµes por sample
â”‚
â”œâ”€â”€ metrics/                       # MÃ©tricas extraÃ­das (237 colunas)
â”‚   â”œâ”€â”€ all_texts.csv             # Dataset principal: 600 textos
â”‚   â””â”€â”€ windowed/                 # AnÃ¡lise temporal: 2990 janelas
â”‚
â”œâ”€â”€ metrics_filtered/              # MÃ©tricas filtradas (65 colunas)
â”‚   â””â”€â”€ all_texts_filtered.csv    # PÃ³s-reduÃ§Ã£o dimensional
â”‚
â”œâ”€â”€ analysis/                      # 6 anÃ¡lises + sÃ­ntese final
â”‚   â”œâ”€â”€ 01_metrics_quality/       # IdentificaÃ§Ã£o de mÃ©tricas problemÃ¡ticas
â”‚   â”œâ”€â”€ 02_author_profiles/       # CaracterizaÃ§Ã£o de estilos autorais
â”‚   â”œâ”€â”€ 03_method_comparison/     # ComparaÃ§Ã£o entre steering methods
â”‚   â”œâ”€â”€ 04_temporal_decay/        # AnÃ¡lise de decaimento vocabular
â”‚   â”œâ”€â”€ 05_consistency/           # Variabilidade intra-mÃ©todo
â”‚   â””â”€â”€ 06_synthesis/             # SÃ­ntese final e implicaÃ§Ãµes linguÃ­sticas
â”‚
â””â”€â”€ scripts/                       # CÃ³digo de extraÃ§Ã£o e anÃ¡lise
    â”œâ”€â”€ metrics_extraction/       # Pipeline de extraÃ§Ã£o (NLTK + UDPipe)
    â””â”€â”€ analysis/                 # 7 scripts de anÃ¡lise dimensional
```

## ğŸ¯ Dataset

**Autores:** 4 (2 literÃ¡rios + 2 enciclopÃ©dicos)
- Clarice Lispector (PT, literÃ¡rio)
- Virginia Woolf (EN, literÃ¡rio)
- Wikipedia PT (enciclopÃ©dico)
- Wikipedia EN (enciclopÃ©dico)

**Estrutura:**
- 60 textos originais (4 autores Ã— 5 tÃ­tulos Ã— 3 samples)
- 540 textos gerados (60 samples Ã— 3 mÃ©todos Ã— 3 repetiÃ§Ãµes)
- **Total:** 600 textos processados

**MÃ©todos de geraÃ§Ã£o:**
1. **Baseline:** Prompt bÃ¡sico sem instruÃ§Ãµes de estilo
2. **Prompt Steering:** Prompt com descriÃ§Ã£o estilomÃ©trica detalhada
3. **Activation Steering:** ManipulaÃ§Ã£o de vetores de ativaÃ§Ã£o (camada 12, escala 1.0)

## ğŸ“ˆ MÃ©tricas ExtraÃ­das

**Pipeline completo:** 237 mÃ©tricas â†’ 65 mÃ©tricas filtradas

**ReduÃ§Ã£o dimensional:**
- Removidas: 126 mÃ©tricas com â‰¥20% NaN (54.8%)
- Removidas: 4 mÃ©tricas constantes
- Removidas: 31 mÃ©tricas de contagem (redundantes com proporÃ§Ãµes)
- Removidas: 8 mÃ©tricas altamente correlacionadas (|r| â‰¥ 0.95)

**MÃ©tricas finais (65):**
- 8 lÃ©xicas bÃ¡sicas (TTR, n-gramas, tamanho mÃ©dio de sentenÃ§as)
- 1 sintÃ¡tica global (mean dependency distance)
- 56 sintÃ¡ticas (proporÃ§Ãµes de UPOS/DEPREL + distÃ¢ncias mÃ©dias)

## ğŸ”¬ AnÃ¡lises Realizadas

### 1. Qualidade das MÃ©tricas
IdentificaÃ§Ã£o de mÃ©tricas problemÃ¡ticas (NaN, variÃ¢ncia zero, correlaÃ§Ãµes).

### 2. Perfis Autorais
CaracterizaÃ§Ã£o de cada autor atravÃ©s de mÃ©tricas discriminativas. **Top 3:**
- `root_prop` (CV=0.784): densidade de oraÃ§Ãµes independentes
- `appos_prop` (CV=0.749): uso de aposiÃ§Ã£o
- `PRON_prop` (CV=0.746): densidade pronominal

### 3. ComparaÃ§Ã£o de MÃ©todos
Preservation scores (1 - distÃ¢ncia euclidiana normalizada):
- **Activation steering:** 0.716 (melhor)
- Baseline: 0.715
- Prompt steering: 0.623 (pior)

### 4. Decaimento Temporal
AnÃ¡lise de evoluÃ§Ã£o de TTR em 5 janelas temporais:
- Originais: slope = +0.0057 (41.7% negativos, quase sem decay)
- Baseline: slope = -0.0934 (90.6% negativos, **16Ã— mais decay**)

### 5. ConsistÃªncia Intra-MÃ©todo
Coeficiente de variaÃ§Ã£o (CV) entre 3 repetiÃ§Ãµes:
- **Activation steering:** 0.189 (melhor, mais determinÃ­stico)
- Baseline: 0.198
- Prompt steering: 0.342 (pior, alta instabilidade)
- **DiferenÃ§a significativa** (Kruskal-Wallis: p<0.0001)

### 6. SÃ­ntese Final
InterpretaÃ§Ã£o linguÃ­stica integrada dos resultados. Ver `analysis/06_synthesis/SINTESE_FINAL.md`.

## ğŸš€ Como Usar

### ExtraÃ§Ã£o de MÃ©tricas (se necessÃ¡rio reprocessar)

```bash
cd scripts/metrics_extraction
python extract_all_metrics.py
```

**Tempo:** ~7-11 horas (UDPipe API Ã© o gargalo)  
**Output:** `metrics/all_texts.csv` (600 textos Ã— 237 mÃ©tricas)

### ReduÃ§Ã£o Dimensional e AnÃ¡lises

```bash
cd scripts/analysis

# AnÃ¡lises individuais (executadas sequencialmente)
python 01_analyze_metrics_quality.py    # Identificar mÃ©tricas problemÃ¡ticas
python 02_filter_metrics.py             # Aplicar filtros (237 â†’ 65)
python 03_create_author_profiles.py     # Perfis autorais
python 04_compare_methods.py            # Comparar steering methods
python 05_analyze_temporal_decay.py     # AnÃ¡lise temporal
python 06_analyze_consistency.py        # ConsistÃªncia intra-mÃ©todo
python 07_generate_final_synthesis.py   # SÃ­ntese final
```

Cada script gera:
- `analysis/{N}_{nome}/data/` - CSVs com resultados
- `analysis/{N}_{nome}/plots/` - VisualizaÃ§Ãµes
- `analysis/{N}_{nome}/report.md` - RelatÃ³rio interpretativo

## ğŸ“Š Principais Resultados

### Hierarquia de Controlabilidade

**Facilmente controlÃ¡vel:**
- MÃ©tricas lÃ©xicas superficiais (tamanho de palavras, TTR)
- DistribuiÃ§Ãµes de classes gramaticais (UPOS)

**Dificilmente controlÃ¡vel:**
- Estruturas sintÃ¡ticas profundas (subordinaÃ§Ã£o, encaixamento)
- RelaÃ§Ãµes de dependÃªncia complexas (apposiÃ§Ã£o, modificaÃ§Ã£o adverbial)

### ImplicaÃ§Ãµes PrÃ¡ticas

**Para aplicaÃ§Ãµes que requerem reprodutibilidade:**
- âœ… Usar activation steering (mais consistente)
- âš ï¸ Evitar prompt steering (alta variabilidade)

**Para preservaÃ§Ã£o de estilo autoral:**
- âœ… Activation steering Ã© superior
- âš ï¸ Baseline tem decaimento temporal artificial
- âŒ Prompt steering diverge muito do original

**LimitaÃ§Ã£o geral:**
- Nenhum mÃ©todo atual controla totalmente estruturas sintÃ¡ticas profundas
- SupervisÃ£o humana permanece necessÃ¡ria para aplicaÃ§Ãµes exigentes

## ğŸ› ï¸ DependÃªncias

```bash
pip install pandas numpy matplotlib seaborn scipy scikit-learn nltk tqdm
```

**Recursos NLTK:**
```python
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('rslp')
```

**UDPipe:** API pÃºblica do LINDAT (requer conexÃ£o internet)

## ğŸ“ CitaÃ§Ã£o

Se usar este trabalho, considere citar:

```bibtex
@misc{linguistics_steering_2025,
  title={Quantitative Analysis of Authorial Style Preservation in LLM-Generated Texts with Steering Methods},
  author={[Seu Nome]},
  year={2025},
  note={Comparative study of baseline, prompt steering, and activation steering techniques}
}
```

## ğŸ“ Modelo Utilizado

- **Modelo:** `openai/gpt-oss-20b`
- **Steering:** Camada 12, escala 1.0
- **MÃ©todo:** Contrafactual (aproximar literÃ¡rio, distanciar enciclopÃ©dico)

## ğŸš§ Roadmap

### Para Adicionar ao RepositÃ³rio:

- [ ] Dataset completo de treinamento (corpus literÃ¡rio + enciclopÃ©dico)
- [ ] Pipeline de cÃ¡lculo de steering vectors
- [ ] Prompts de geraÃ§Ã£o (baseline, prompt steering, activation steering)
- [ ] Scripts de geraÃ§Ã£o dos 540 textos
- [ ] HiperparÃ¢metros de geraÃ§Ã£o (temperatura, top-p, etc.)
- [ ] Notebook demonstrativo do processo completo

**ContribuiÃ§Ãµes e questÃµes:** Abra uma issue para discutir componentes ausentes ou metodologia.

## ğŸ“„ LicenÃ§a

[Especifique a licenÃ§a aqui]

---

**Status:** âœ… AnÃ¡lise linguÃ­stica completa | âš ï¸ Pipeline de geraÃ§Ã£o nÃ£o incluÃ­do  
**Ãšltima atualizaÃ§Ã£o:** Novembro 2025
